{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff72ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T17:28:22.314833Z",
     "iopub.status.busy": "2022-04-24T17:28:22.314507Z",
     "iopub.status.idle": "2022-04-24T17:28:23.120586Z",
     "shell.execute_reply": "2022-04-24T17:28:23.120030Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.812701,
     "end_time": "2022-04-24T17:28:23.122483",
     "exception": false,
     "start_time": "2022-04-24T17:28:22.309782",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aiujdm2/.local/share/virtualenvs/market_watch-dtlP-L11/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from re import M\n",
    "import ptan\n",
    "import pathlib\n",
    "import gym.wrappers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from ignite.engine import Engine\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger\n",
    "from src.models.lib import environ, models, common, validation\n",
    "upstream = ['combine_fred_yahoo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90e20e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T17:28:23.126969Z",
     "iopub.status.busy": "2022-04-24T17:28:23.126770Z",
     "iopub.status.idle": "2022-04-24T17:28:23.129721Z",
     "shell.execute_reply": "2022-04-24T17:28:23.129194Z"
    },
    "papermill": {
     "duration": 0.006491,
     "end_time": "2022-04-24T17:28:23.131250",
     "exception": false,
     "start_time": "2022-04-24T17:28:23.124759",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "upstream = {\n",
    "    \"combine_fred_yahoo\": {\n",
    "        \"nb\": \"/Users/aiujdm2/market_watch/output/notebooks/combine_fred_yahoo.ipynb\",\n",
    "        \"data\": \"/Users/aiujdm2/market_watch/output/data/raw/fred_yahoo.xlsx\",\n",
    "    }\n",
    "}\n",
    "product = {\"nb\": \"/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dbaa0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T17:28:23.134949Z",
     "iopub.status.busy": "2022-04-24T17:28:23.134739Z",
     "iopub.status.idle": "2022-04-24T17:28:23.153600Z",
     "shell.execute_reply": "2022-04-24T17:28:23.153054Z"
    },
    "papermill": {
     "duration": 0.022737,
     "end_time": "2022-04-24T17:28:23.155226",
     "exception": false,
     "start_time": "2022-04-24T17:28:23.132489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(\n",
    "    saves_dir=\"output\",\n",
    "    batch_size=32,\n",
    "    bars_count=10,\n",
    "\n",
    "    eps_start=1.0,\n",
    "    eps_final=0.1,\n",
    "    eps_steps=1000000,\n",
    "\n",
    "    gamma=0.99,\n",
    "\n",
    "    replay_size=100000,\n",
    "    replay_initial=1000,\n",
    "    reward_steps=2,\n",
    "    learning_rate=0.0001,\n",
    "    states_to_evaluate=1000,\n",
    "\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    run_name='test',\n",
    "    ticker=os.environ.get('TRADE_TICKER', 'TSLA'),\n",
    "    n_val=50\n",
    "):\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "    saves_path = pathlib.Path(saves_dir) / f\"conv-{run_name}\"\n",
    "    saves_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    features = [\n",
    "        'Close',  # close price should be here since it's used in cur_close method of state\n",
    "        'High',\n",
    "        'Low',\n",
    "        'Open'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # try to fetch data from ploomber build step\n",
    "        stock_data_path = upstream['combine_fred_yahoo']['data']\n",
    "        # TODO: weights upstream\n",
    "        weights_data_path = os.path.expanduser(os.environ.get(\n",
    "            'WEIGHTS_PATH', \n",
    "'~/market_watch/data/tfidf_vals.txt'))\n",
    "        # weights_data_path = upstream['combine_fred_yahoo']['data']\n",
    "    except Exception:\n",
    "        # fallbalck to env variables\n",
    "        stock_data_path = os.environ.get(\n",
    "            'DATA_PATH', '~/Downloads/fred_yahoo-2.xlsx')\n",
    "\n",
    "    dfs = pd.read_excel(stock_data_path, sheet_name=features)\n",
    "\n",
    "    cols = None\n",
    "    for feature in features:\n",
    "        if cols is None:\n",
    "            cols = dfs[feature].columns\n",
    "        else:\n",
    "            cols = np.intersect1d(cols, dfs[feature].columns)\n",
    "\n",
    "    cols = [c for c in cols if 'date' not in c.lower()]\n",
    "    weights_json = defaultdict(int)\n",
    "    with open(weights_data_path) as f:\n",
    "        weights_json.update(json.loads(f.read()))\n",
    "\n",
    "    weights = [weights_json[c] for c in cols]\n",
    "\n",
    "    target_stock_index = cols.index(ticker)\n",
    "    data = np.array([\n",
    "        dfs[feature][cols] for feature in features\n",
    "    ]).astype(np.float32)\n",
    "    data_train = data[:, :-n_val, :]\n",
    "    data_validation = data[:, -n_val:, :]\n",
    "\n",
    "    env = environ.MarketWatchStocksEnv(\n",
    "        data_train, bars_count=bars_count, target_index=target_stock_index, weights=weights)\n",
    "    env_val = environ.MarketWatchStocksEnv(\n",
    "        data_validation, bars_count=bars_count, target_index=target_stock_index, weights=weights)\n",
    "\n",
    "    env = gym.wrappers.TimeLimit(env, max_episode_steps=20)\n",
    "\n",
    "    net = models.DQNConv1DMarketWatch(\n",
    "        env.observation_space.shape, env.action_space.n, bars_count).to(device)\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(eps_start)\n",
    "    eps_tracker = ptan.actions.EpsilonTracker(\n",
    "        selector, eps_start, eps_final, eps_steps)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device,\n",
    "                                preprocessor=lambda x: common.state_preprocessor(x, device=device))\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "        env, agent, gamma, steps_count=reward_steps)\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(\n",
    "        exp_source, replay_size)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    def process_batch(engine, batch):\n",
    "        optimizer.zero_grad()\n",
    "        loss_v = common.calc_loss(\n",
    "            batch, net, tgt_net.target_model,\n",
    "            gamma=gamma ** reward_steps, device=device)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        eps_tracker.frame(engine.state.iteration)\n",
    "\n",
    "        if getattr(engine.state, \"eval_states\", None) is None:\n",
    "            eval_states = buffer.sample(states_to_evaluate)\n",
    "            eval_states = [np.array(transition.state, copy=False)\n",
    "                           for transition in eval_states]\n",
    "            engine.state.eval_states = np.array(eval_states, copy=False)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss_v.item(),\n",
    "            \"epsilon\": selector.epsilon,\n",
    "        }\n",
    "\n",
    "    engine = Engine(process_batch)\n",
    "    tb = common.setup_ignite(engine, exp_source, f\"conv-{run_name}\",\n",
    "                             extra_metrics=('values_mean',))\n",
    "\n",
    "    @engine.on(ptan.ignite.PeriodEvents.ITERS_10_COMPLETED)\n",
    "    def sync_eval(engine: Engine):\n",
    "        tgt_net.sync()\n",
    "\n",
    "        mean_val = common.calc_values_of_states(\n",
    "            engine.state.eval_states, net, device=device)\n",
    "        engine.state.metrics[\"values_mean\"] = mean_val\n",
    "        is_first = False\n",
    "        if getattr(engine.state, \"best_mean_val\", None) is None:\n",
    "            engine.state.best_mean_val = mean_val\n",
    "            is_first = True\n",
    "\n",
    "        if engine.state.best_mean_val < mean_val or is_first:\n",
    "            print(\"%d: Best mean value updated %.3f -> %.3f\" % (\n",
    "                engine.state.iteration, engine.state.best_mean_val,\n",
    "                mean_val))\n",
    "            path = saves_path / (\"mean_value_%.3f.data\" % mean_val)\n",
    "            torch.save(net.state_dict(), path)\n",
    "            engine.state.best_mean_val = mean_val\n",
    "        # else:\n",
    "        #     print(\n",
    "        #         f'mean_val ${mean_val}, less than best {engine.state.best_mean_val}')\n",
    "\n",
    "    test_metrics = []\n",
    "    validation_metrics = []\n",
    "    @engine.on(ptan.ignite.PeriodEvents.ITERS_10_COMPLETED)\n",
    "    def validate(engine: Engine):\n",
    "        res_test = validation.validation_run(env_val, net, device=device)\n",
    "        test_metrics.append(res_test)\n",
    "        with open(saves_path / 'metrics_test.json', 'w') as f:\n",
    "            json.dump(test_metrics, f)\n",
    "        res = validation.validation_run(env_val, net, device=device)\n",
    "        validation_metrics.append(res)\n",
    "        print(\"%d: val: %s\" % (engine.state.iteration, res))\n",
    "        for key, val in res.items():\n",
    "            engine.state.metrics[key + \"_val\"] = val\n",
    "        val_reward = res['episode_reward']\n",
    "        is_new = False\n",
    "        if getattr(engine.state, \"best_val_reward\", None) is None:\n",
    "            engine.state.best_val_reward = val_reward\n",
    "            is_new = True\n",
    "        if engine.state.best_val_reward < val_reward or is_new:\n",
    "            print(\"Best validation reward updated: %.3f -> %.3f, model saved\" % (\n",
    "                engine.state.best_val_reward, val_reward\n",
    "            ))\n",
    "            engine.state.best_val_reward = val_reward\n",
    "            path = saves_path / (\"val_reward-%.3f.data\" % val_reward)\n",
    "            torch.save(net.state_dict(), path)\n",
    "        with open(saves_path / 'metrics.json', 'w') as f:\n",
    "            json.dump(validation_metrics, f)\n",
    "\n",
    "\n",
    "\n",
    "    event = ptan.ignite.PeriodEvents.ITERS_100_COMPLETED\n",
    "    tst_metrics = [m + \"_tst\" for m in validation.METRICS]\n",
    "    tst_handler = tb_logger.OutputHandler(\n",
    "        tag=\"test\", metric_names=tst_metrics)\n",
    "    tb.attach(engine, log_handler=tst_handler, event_name=event)\n",
    "\n",
    "    val_metrics = [m + \"_val\" for m in validation.METRICS]\n",
    "    val_handler = tb_logger.OutputHandler(\n",
    "        tag=\"validation\", metric_names=val_metrics)\n",
    "    tb.attach(engine, log_handler=val_handler, event_name=event)\n",
    "    yield net, agent, data, env\n",
    "\n",
    "    engine.run(common.batch_generator(buffer, replay_initial, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f306a",
   "metadata": {
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-04-24T17:28:23.156648",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    runner = train_model(replay_initial=10)\n",
    "    net, agent, data, env = next(runner)\n",
    "    print('running the training process')\n",
    "    next(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334619b5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "exception": null,
   "input_path": "/var/folders/b0/4tc1nfbd6z7_vhx4nxcj2n91c0l9h6/T/tmpydrhhz2h.ipynb",
   "output_path": "/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb",
   "parameters": {
    "product": {
     "nb": "/Users/aiujdm2/market_watch/output/notebooks/train_model.ipynb"
    },
    "upstream": {
     "combine_fred_yahoo": {
      "data": "/Users/aiujdm2/market_watch/output/data/raw/fred_yahoo.xlsx",
      "nb": "/Users/aiujdm2/market_watch/output/notebooks/combine_fred_yahoo.ipynb"
     }
    }
   },
   "start_time": "2022-04-24T17:28:21.392204"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}